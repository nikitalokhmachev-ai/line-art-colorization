{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as M\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import IPython.display as ipd\n",
    "\n",
    "import requests\n",
    "\n",
    "from xdog import to_sketch\n",
    "from data_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels=256, out_channels=256, stride=1, cardinality=32, dilate=1):\n",
    "        super(ResNeXtBottleneck, self).__init__()\n",
    "        \n",
    "        D = out_channels // 2\n",
    "        self.out_channels = out_channels\n",
    "        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv_conv = nn.Conv2d(D, D, kernel_size=2 + stride, stride=stride, padding=dilate, dilation=dilate, groups=cardinality, bias=False)\n",
    "        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1:\n",
    "            self.shortcut.add_module('shortcut', nn.AvgPool2d(2, stride=2))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.conv_reduce.forward(x)\n",
    "        bottleneck = F.leaky_relu(bottleneck, 0.2, True)\n",
    "        bottleneck = self.conv_conv.forward(bottleneck)\n",
    "        bottleneck = F.leaky_relu(bottleneck, 0.2, True)\n",
    "        bottleneck = self.conv_expand.forward(bottleneck)\n",
    "        x = self.shortcut.forward(x)\n",
    "        \n",
    "        return x + bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf=64, feat=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.feat = feat\n",
    "        if feat:\n",
    "            add_channels = 512\n",
    "        else:\n",
    "            add_channels = 0\n",
    "        #WHY CONV2D and not CONVTRANSPOSE2D\n",
    "        self.toH = self._block(4, ngf, kernel_size=7, stride=1, padding=3)\n",
    "        self.to0 = self._block(1, ngf // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.to1 = self._block(ngf // 2, ngf, kernel_size=4, stride=2, padding=1)\n",
    "        self.to2 = self._block(ngf, ngf * 2, kernel_size=4, stride=2, padding=1)\n",
    "        self.to3 = self._block(ngf * 3, ngf * 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.to4 = self._block(ngf * 4, ngf * 8, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        tunnel4 = nn.Sequential(*[ResNeXtBottleneck(ngf * 8, ngf * 8, cardinality=32, dilate=1) for _ in range(20)])\n",
    "        \n",
    "        self.tunnel4 = nn.Sequential(self._block(ngf * 8 + add_channels, ngf * 8, kernel_size=3, stride=1, padding=1),\n",
    "                                     tunnel4,\n",
    "                                     nn.Conv2d(ngf * 8, ngf * 16, kernel_size = 3, stride=1, padding=1),\n",
    "                                     nn.PixelShuffle(2),\n",
    "                                     nn.LeakyReLU(0.2, True))\n",
    "        \n",
    "        depth = 2\n",
    "        \n",
    "        tunnel = [ResNeXtBottleneck(ngf * 4, ngf * 4, cardinality=32, dilate=1) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 4, ngf * 4, cardinality=32, dilate=2) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 4, ngf * 4, cardinality=32, dilate=4) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 4, ngf * 4, cardinality=32, dilate=2),\n",
    "                   ResNeXtBottleneck(ngf * 4, ngf * 4, cardinality=32, dilate=1)]\n",
    "        tunnel3 = nn.Sequential(*tunnel)\n",
    "        \n",
    "        self.tunnel3 = nn.Sequential(self._block(ngf * 8, ngf * 4, kernel_size=3, stride=1, padding=1),\n",
    "                                     tunnel3,\n",
    "                                     nn.Conv2d(ngf * 4, ngf * 8, kernel_size=3, stride=1, padding=1),\n",
    "                                     nn.PixelShuffle(2), \n",
    "                                     nn.LeakyReLU(0.2, True))\n",
    "        \n",
    "        tunnel = [ResNeXtBottleneck(ngf * 2, ngf * 2, cardinality=32, dilate=1) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 2, ngf * 2, cardinality=32, dilate=2) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 2, ngf * 2, cardinality=32, dilate=4) for _ in range(depth)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf * 2, ngf * 2, cardinality=32, dilate=2),\n",
    "                   ResNeXtBottleneck(ngf * 2, ngf * 2, cardinality=32, dilate=1)]\n",
    "        tunnel2 = nn.Sequential(*tunnel)\n",
    "        \n",
    "        self.tunnel2 = nn.Sequential(self._block(ngf * 4, ngf * 2, kernel_size=3, stride=1, padding=1),\n",
    "                                     tunnel2,\n",
    "                                     nn.Conv2d(ngf * 2, ngf * 4, kernel_size=3, stride=1, padding=1),\n",
    "                                     nn.PixelShuffle(2), \n",
    "                                     nn.LeakyReLU(0.2, True))\n",
    "        \n",
    "        tunnel = [ResNeXtBottleneck(ngf, ngf, cardinality=16, dilate=1)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf, ngf, cardinality=16, dilate=2)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf, ngf, cardinality=16, dilate=4)]\n",
    "        tunnel += [ResNeXtBottleneck(ngf, ngf, cardinality=16, dilate=2),\n",
    "                   ResNeXtBottleneck(ngf, ngf, cardinality=16, dilate=1)]\n",
    "        tunnel1 = nn.Sequential(*tunnel)\n",
    "        \n",
    "        self.tunnel1 = nn.Sequential(self._block(ngf * 2, ngf, kernel_size=3, stride=1, padding=1),\n",
    "                                     tunnel1,\n",
    "                                     nn.Conv2d(ngf, ngf * 2, kernel_size=3, stride=1, padding=1),\n",
    "                                     nn.PixelShuffle(2), \n",
    "                                     nn.LeakyReLU(0.2, True))\n",
    "        \n",
    "        self.exit = nn.Conv2d(ngf, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, sketch, hint, sketch_feat):\n",
    "        hint = self.toH(hint)\n",
    "        \n",
    "        x0 = self.to0(sketch)\n",
    "        x1 = self.to1(x0)\n",
    "        x2 = self.to2(x1)\n",
    "        x3 = self.to3(torch.cat([x2, hint], 1))\n",
    "        x4 = self.to4(x3)\n",
    "        \n",
    "        if self.feat:\n",
    "            x = self.tunnel4(torch.cat([x4, sketch_feat], 1))\n",
    "            x = self.tunnel3(torch.cat([x, x3], 1))\n",
    "            x = self.tunnel2(torch.cat([x, x2], 1))\n",
    "            x = self.tunnel1(torch.cat([x, x1], 1))\n",
    "            x = torch.tanh(self.exit(torch.cat([x, x0], 1)))\n",
    "        else:\n",
    "            x = self.tunnel4(x4)\n",
    "            x = self.tunnel3(torch.cat([x, x3], 1))\n",
    "            x = self.tunnel2(torch.cat([x, x2], 1))\n",
    "            x = self.tunnel1(torch.cat([x, x1], 1))\n",
    "            x = torch.tanh(self.exit(torch.cat([x, x0], 1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, feat=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.feat = feat\n",
    "        \n",
    "        if feat:\n",
    "            add_channels = ndf * 8\n",
    "            ks = 4\n",
    "        else:\n",
    "            add_channels = 0\n",
    "            ks = 3\n",
    "            \n",
    "        self.feed = nn.Sequential(\n",
    "            self._block(3, ndf, kernel_size=7, stride=1, padding=1),\n",
    "            self._block(ndf, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            \n",
    "            ResNeXtBottleneck(ndf, ndf, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf, ndf, cardinality=8, dilate=1, stride=2),\n",
    "            self._block(ndf, ndf * 2, kernel_size=1, stride=1, padding=0),\n",
    "            \n",
    "            ResNeXtBottleneck(ndf * 2, ndf * 2, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf * 2, ndf * 2, cardinality=8, dilate=1, stride=2),\n",
    "            self._block(ndf * 2, ndf * 4, kernel_size=1, stride=1, padding=0),\n",
    "            \n",
    "            ResNeXtBottleneck(ndf * 4, ndf * 4, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf * 4, ndf * 4, cardinality=8, dilate=1, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.feed2 = nn.Sequential(\n",
    "            self._block(ndf * 4 + add_channels, ndf * 8, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1, stride=2),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1, stride=2),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1, stride=2),\n",
    "            ResNeXtBottleneck(ndf * 8, ndf * 8, cardinality=8, dilate=1),\n",
    "            \n",
    "            self._block(ndf * 8, ndf * 8, kernel_size=ks, stride=1, padding=0),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(512, 1)\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels,\n",
    "                      out_channels,\n",
    "                      kernel_size,\n",
    "                      stride,\n",
    "                      padding,\n",
    "                      bias=False),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, color, sketch_feat=None):\n",
    "        x = self.feed(color)\n",
    "        \n",
    "        if self.feat:\n",
    "            x = self.feed2(torch.cat([x, sketch_feat], 1))\n",
    "        else:\n",
    "            x = self.feed2(x)\n",
    "        \n",
    "        out = self.out(x.view(color.size(0), -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalFeatureExtractor, self).__init__()\n",
    "        vgg16 = M.vgg16(pretrained=True)\n",
    "        vgg16.features = nn.Sequential(\n",
    "            *list(vgg16.features.children())[:9]\n",
    "        )\n",
    "        self.model = vgg16.features\n",
    "        self.register_buffer('mean', torch.FloatTensor([0.485 - 0.5, 0.456 - 0.5, 0.406 - 0.5]).view(1, 3, 1, 1))\n",
    "        self.register_buffer('std', torch.FloatTensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model((images.mul(0.5) - self.mean) / self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, gp_weight=10, device='cpu'):\n",
    "    bs, c, h, w = real.shape\n",
    "    epsilon = torch.rand((bs, 1, 1, 1)).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "    interpolated_images.requires_grad = True\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores).to(device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    #gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_penalty = torch.mean((gradient.norm(2, dim=1) - 1)**2) * gp_weight\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(gen, sk, hnt = None):\n",
    "    #sk = Image.open(sketch_path).convert('L')\n",
    "    sk = etrans(sk)\n",
    "\n",
    "    pad_w = 16 - sk.shape[1] % 16 if sk.shape[1] % 16 != 0 else 0\n",
    "    pad_h = 16 - sk.shape[2] % 16 if sk.shape[2] % 16 != 0 else 0\n",
    "    pad = nn.ZeroPad2d((pad_h, 0, pad_w, 0))\n",
    "    sk = pad(sk)\n",
    "\n",
    "    sk = sk.unsqueeze(0)\n",
    "    sk = sk.to(device)\n",
    "\n",
    "    if hnt == None:\n",
    "        hnt = torch.zeros((1, 4, sk.shape[2]//4, sk.shape[3]//4))\n",
    "\n",
    "    hnt = hnt.to(device)\n",
    "\n",
    "    img_gen = gen(sk, hnt, sketch_feat=None).squeeze(0)\n",
    "    img_gen = denormalize(img_gen) * 255\n",
    "    img_gen = img_gen.permute(1,2,0).detach().cpu().numpy().astype(np.uint8)\n",
    "    return Image.fromarray(img_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_link(gen, link):\n",
    "    img_orig = Image.open(requests.get(link, stream=True).raw).convert('RGB')\n",
    "    sketch_test = to_sketch(img_orig, sigma=0.5, k=5, gamma=0.92, epsilon=-1, phi=10e15, area_min=2)\n",
    "    return predict_img(gen, sketch_test, hnt = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etrans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ITER = 250000\n",
    "IMG_SIZE = 512\n",
    "BS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "WORKERS = 4\n",
    "\n",
    "DITERS = 1\n",
    "\n",
    "ADVERSARIAL_WEIGHT = 1e-4\n",
    "GP_WEIGHT = 10\n",
    "DRIFT = 1e-3\n",
    "\n",
    "NGF, NDF = 64, 64\n",
    "\n",
    "IMG_PATH = 'alacgan_data'\n",
    "\n",
    "OUT_FOLDER = 'alacgan_mdl'\n",
    "OUT_IMG_FOLDER = 'alacgan_res'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pths = list(map(lambda x: os.path.join(IMG_PATH, 'pics', x), os.listdir(os.path.join(IMG_PATH, 'pics'))))[:-1]\n",
    "for pth in pths:\n",
    "    print(Image.open(pth).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(feat=False).to(device)\n",
    "critic = Discriminator(feat=False).to(device)\n",
    "globf = GlobalFeatureExtractor().to(device)\n",
    "\n",
    "if CONTINUE_TRAINING:\n",
    "    last_batch = max([int(re.sub('\\D', '', el)) for el in os.listdir('alacgan_mdl') if 'gen' in el])\n",
    "    gen.load_state_dict(torch.load(os.path.join(OUT_FOLDER, 'gen_' + str(last_batch) + '.pth')))\n",
    "    critic.load_state_dict(torch.load(os.path.join(OUT_FOLDER, 'critic_' + str(last_batch) + '.pth')))\n",
    "    print('Continuing from {} batch...'.format(last_batch))\n",
    "\n",
    "for param in globf.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "links = ['http://static.demilked.com/wp-content/uploads/2014/03/detailed-black-pen-drawings-kerby-rosanes-thumb640.jpg',\n",
    "    'https://i.pinimg.com/474x/8c/84/72/8c847264ac638f6b047ae62eddd0d7ab--dragon-sketch-dragon-drawings.jpg',\n",
    "        'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSpfke4P4Tx3CR9bfTGy1nZF0WH37L8olTigw&usqp=CAU',\n",
    "        'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQCw8f0v-AJkLKGSozjt-ZER6fIEew7nk_MFw&usqp=CAU',\n",
    "         'https://flowers.tn/wp-content/uploads/2018/08/Flowers-Drawings-Inspiration-A-detailed-flower-line-art-feel-free-to-download-and-colour.jpg',\n",
    "         'https://media.istockphoto.com/vectors/china-detailed-skyline-vector-background-line-illustration-line-art-vector-id515527320',\n",
    "        'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSStzDp24RHFChp_Sd02xAK1zram70szPBW3w&usqp=CAU',\n",
    "        'https://mymodernmet.com/wp/wp-content/uploads/2018/03/coloring-book-pages.jpg']\n",
    "\n",
    "for link in links:\n",
    "    img_link = Image.open(requests.get(link, stream=True).raw).convert('RGB')\n",
    "    sketch_tst = to_sketch(img_link, sigma=0.4, k=4.5, gamma=0.93, epsilon=-1, phi=10e15, area_min=2).convert('L')\n",
    "\n",
    "    img_to_disp = predict_img(gen, sketch_tst, hnt = None)\n",
    "    ipd.display(img_to_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_MSE = nn.MSELoss().to(device)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LR, betas=(0.5, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LR, betas=(0.5, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_gen = torch.optim.lr_scheduler.CosineAnnealingLR(opt_gen, TOTAL_ITER, eta_min=1e-7)\n",
    "lr_scheduler_critic = torch.optim.lr_scheduler.CosineAnnealingLR(opt_critic, TOTAL_ITER, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('alacgan_data', img_size=IMG_SIZE, seed=5, total_iter=TOTAL_ITER, bs=BS, diters=DITERS, last_iter=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "link = 'https://cdn.vox-cdn.com/thumbor/J2XSqgAqREtpkGAWa6rMhkHA1Y0=/0x0:1600x900/1400x933/filters:focal(672x322:928x578):no_upscale()/cdn.vox-cdn.com/uploads/chorus_image/image/66320060/Tanjiro__Demon_Slayer_.0.png'\n",
    "img_link = Image.open(requests.get(link, stream=True).raw).convert('RGB')\n",
    "sketch_tst = to_sketch(img_link, sigma=0.4, k=4.5, gamma=0.93, epsilon=-1, phi=10e15, area_min=2).convert('L')\n",
    "\n",
    "if OUT_FOLDER not in os.listdir():\n",
    "    os.mkdir(OUT_FOLDER)\n",
    "\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    color, color_down, sketch = data\n",
    "    mask = mask_gen(IMG_SIZE, BS)\n",
    "    hint = torch.cat((color_down * mask, mask), 1)\n",
    "    color, hint, sketch = color.to(device), hint.to(device), sketch.to(device)\n",
    "    \n",
    "    lr_scheduler_gen.step(batch_idx)\n",
    "    lr_scheduler_critic.step(batch_idx)\n",
    "    \n",
    "    current_lr = lr_scheduler_gen.get_lr()[0]\n",
    "    \n",
    "    if color.shape[0] == BS:\n",
    "        for p in critic.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in gen.parameters():\n",
    "            p.requires_grad = False  \n",
    "            \n",
    "        for _ in range(DITERS):\n",
    "            critic.zero_grad()\n",
    "                       \n",
    "            with torch.no_grad():\n",
    "                #sketch_feat = netI(sketch).detach()\n",
    "                fake_color = gen(sketch, hint, sketch_feat=None).detach()\n",
    "                \n",
    "            critic_conf_fake = critic(fake_color)\n",
    "            critic_conf_fake = critic_conf_fake.mean(0).view(1)\n",
    "            critic_conf_fake.backward(retain_graph=True)\n",
    "            \n",
    "            critic_conf_real = critic(color)\n",
    "            critic_conf_real = critic_conf_real.mean(0).view(1)\n",
    "            \n",
    "            critic_conf_err = critic_conf_real - critic_conf_fake\n",
    "            \n",
    "            loss_critic_real = critic_conf_real.pow(2) * DRIFT - critic_conf_real\n",
    "            loss_critic_real.backward(retain_graph=True)\n",
    "            \n",
    "            gp = gradient_penalty(critic, color, fake_color, device=device)\n",
    "            gp.backward()\n",
    "            \n",
    "            opt_critic.step()\n",
    "\n",
    "        \n",
    "        for p in critic.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in gen.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        gen.zero_grad()\n",
    "        \n",
    "        fake_color = gen(sketch, hint, sketch_feat=None)\n",
    "        \n",
    "        critic_conf_fake = critic(fake_color)\n",
    "        adv_loss = - critic_conf_fake.mean() * ADVERSARIAL_WEIGHT\n",
    "        adv_loss.backward(retain_graph=True)\n",
    "        \n",
    "        feat_fake = globf(fake_color)\n",
    "        with torch.no_grad():\n",
    "            feat_real = globf(color)\n",
    "            \n",
    "        content_loss = criterion_MSE(feat_fake, feat_real)\n",
    "        content_loss.backward()\n",
    "        \n",
    "        opt_gen.step()\n",
    "        print(f'adv_loss:{adv_loss}, content_loss:{content_loss}, critic_loss:{critic_conf_err.cpu().detach().numpy()[0]}, penalty_loss:{loss_critic_real.cpu().detach().numpy()[0]}')\n",
    "        '''with torch.no_grad():\n",
    "            img_to_disp = predict_img(gen, sketch_tst, hnt = None)\n",
    "            ipd.display(img_to_disp.resize((img_to_disp.width//4, img_to_disp.height//4)))'''\n",
    "            \n",
    "            \n",
    "        if batch_idx % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                img_to_disp = predict_img(gen, sketch_tst, hnt = None)\n",
    "                img_to_disp.save(os.path.join(OUT_IMG_FOLDER, f'img_{batch_idx}.jpg'), 'JPEG')\n",
    "            torch.save(gen.state_dict(), os.path.join(OUT_FOLDER, f'gen_{batch_idx}.pth'))\n",
    "            torch.save(critic.state_dict(), os.path.join(OUT_FOLDER, f'critic_{batch_idx}.pth'))\n",
    "            \n",
    "        ipd.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''links = ['https://cdn.vox-cdn.com/thumbor/HyOhm280EOQO2ubcOZCSONkDGb8=/0x0:1200x675/1200x800/filters:focal(504x242:696x434)/cdn.vox-cdn.com/uploads/chorus_image/image/68567666/Dr._STONE_Season_2_release_date_Episode_24_ending_with_Stone_Wars_Dr._STONE_manga_compared_to_the_anime_Spoilers.0.jpg',\n",
    "        'https://jw-webmagazine.com/wp-content/uploads/2020/03/Kimetsu-no-YaibaDemon-Slayer.jpg',\n",
    "        'https://dthezntil550i.cloudfront.net/00resources/images/page/banner/2f/2fb10643-cd06-461e-8538-2ed6823833ec.jpg',\n",
    "        'https://live-production.wcms.abc-cdn.net.au/b481c9acb8e5e283f276dfcd7889b593?impolicy=wcms_crop_resize&cropH=576&cropW=863&xPos=80&yPos=0&width=862&height=575',\n",
    "        'https://cdn.mos.cms.futurecdn.net/eVyt9jnUrLBSvSwW6pScj9-320-80.jpg',\n",
    "        'https://i.pinimg.com/564x/9a/ba/60/9aba6040f5c0af8c93b388f5df24c121.jpg',\n",
    "        'https://assets.puzzlefactory.pl/puzzle/258/817/original.jpg']\n",
    "get_data(links, img_path='alacgan_data', line_widths=[0.3, 0.5])'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
